{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Reverse Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from contextlib import closing\n",
    "from dataclasses import dataclass, field\n",
    "from nltk.corpus import stopwords\n",
    "from typing import List, Set\n",
    "import itertools\n",
    "import json\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sqlite3\n",
    "import string\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/j/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/j/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.nltk.org/api/nltk.tokenize.punkt.html\n",
    "nltk.download(\"punkt\")\n",
    "# https://www.nltk.org/howto/corpus.html?highlight=stopwords#word-lists-and-lexicons\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class Document:\n",
    "    id: str = field(repr=False)\n",
    "    url: str\n",
    "    blob: bytes = field(repr=False, hash=False)\n",
    "    score: float = field(default=0.0)\n",
    "\n",
    "\n",
    "class Crawler:\n",
    "    \"\"\"Crawl and index documents into (id, url, blob)\"\"\"\n",
    "\n",
    "    def __init__(self, db_path):\n",
    "        self.db_path = db_path\n",
    "\n",
    "        create_sql = \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS docs\n",
    "                (id TEXT PRIMARY KEY, url TEXT UNIQUE, blob BLOB)\"\"\"\n",
    "\n",
    "        with closing(sqlite3.connect(self.db_path)) as conn:\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(create_sql)\n",
    "\n",
    "    def __call__(self, url) -> Document:\n",
    "        insert_sql = \"INSERT INTO docs (id, url, blob) VALUES (?, ?, ?)\"\n",
    "        check_sql = \"SELECT id, url, blob FROM docs WHERE url = ?\"\n",
    "        blob = requests.get(url, stream=True).content\n",
    "\n",
    "        with closing(sqlite3.connect(self.db_path)) as conn:\n",
    "            cursor = conn.cursor()\n",
    "\n",
    "            exists = cursor.execute(check_sql, (url,)).fetchone()\n",
    "            if exists:\n",
    "                (id, url, blob) = exists\n",
    "                return Document(id, url, blob)\n",
    "            else:\n",
    "                doc = Document(str(uuid.uuid4()), url, blob)\n",
    "                cursor.execute(insert_sql, (doc.id, url, blob))\n",
    "                conn.commit()\n",
    "                return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://blog.jabid.in\",\n",
    "    \"https://blog.jabid.in/2020/02/29/track.html\",\n",
    "    \"https://blog.jabid.in/2019/10/25/why.html\",\n",
    "    \"https://blog.jabid.in/2019/01/13/monzo.html\",\n",
    "    \"https://blog.jabid.in/2019/05/10/amsterdam.html\",\n",
    "]\n",
    "\n",
    "crawler = Crawler(\"search.db\")\n",
    "docs = [crawler(url) for url in urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc) -> Set[str]:\n",
    "    \"\"\"Tokenize a document to a list of words.\"\"\"\n",
    "\n",
    "    text = str(doc.blob) if isinstance(doc, Document) else str(doc)\n",
    "    exclude = set(string.punctuation) - set(stopwords.words(\"english\"))\n",
    "    tokens = set(nltk.word_tokenize(text)) - exclude\n",
    "    return {token.lower() for token in tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Indexer:\n",
    "    \"\"\"Build a reverse index from token => [documents]\"\"\"\n",
    "\n",
    "    def __init__(self, db_path):\n",
    "        self.db_path = db_path\n",
    "\n",
    "        drop_sql = \"DROP TABLE reverse_index;\"\n",
    "        create_sql = \"CREATE TABLE IF NOT EXISTS reverse_index \\\n",
    "                (token TEXT PRIMARY KEY, documents JSON)\"\n",
    "\n",
    "        with closing(sqlite3.connect(self.db_path)) as conn:\n",
    "            conn.execute(\"PRAGMA foreign_keys = ON\")\n",
    "            conn.execute(drop_sql)\n",
    "            conn.execute(create_sql)\n",
    "            conn.commit()\n",
    "\n",
    "    def __call__(self, doc: Document):\n",
    "        tokens = tokenize(doc)\n",
    "\n",
    "        select_sql = \"SELECT documents FROM reverse_index WHERE token = ?\"\n",
    "        insert_sql = \"REPLACE INTO reverse_index (token, documents) VALUES (?, json(?))\"\n",
    "\n",
    "        with closing(sqlite3.connect(self.db_path)) as conn:\n",
    "            for token in tokens:\n",
    "                result = conn.execute(select_sql, (token,)).fetchone()\n",
    "                documents = set(json.loads(result[0]) if result else [])\n",
    "                documents.add(doc.id)\n",
    "                conn.execute(insert_sql, (token, json.dumps(list(documents))))\n",
    "\n",
    "            conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexer = Indexer(\"search.db\")\n",
    "[indexer(doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://blog.jabid.in/2019/01/13/monzo.html</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://blog.jabid.in</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           url  score\n",
       "0  https://blog.jabid.in/2019/01/13/monzo.html    0.5\n",
       "1                        https://blog.jabid.in    0.5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Search:\n",
    "    def __init__(self, db_path):\n",
    "        self.db = sqlite3.connect(f\"file:{db_path}?mode=ro\")\n",
    "\n",
    "    def fetch_one(self, id: str) -> Document:\n",
    "        sql = \"SELECT id, url, blob FROM docs WHERE id = ?;\"\n",
    "        if exists := self.db.execute(sql, (id,)).fetchone():\n",
    "            (id, url, blob) = exists\n",
    "            return Document(id, url, blob)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def fetch_many(self, ids: List[str] | Set[str]) -> List[Document]:\n",
    "        return [self.fetch_one(id) for id in ids]\n",
    "\n",
    "    def candidates(self, tokens: List[str]):\n",
    "        \"Candidates for the query from reverse index\"\n",
    "\n",
    "        def one(token: str):\n",
    "            reverse_index_sql = \"select token, documents from reverse_index where token = ?\"\n",
    "            row = self.db.execute(reverse_index_sql, (token,)).fetchone()\n",
    "            ids = set(json.loads(row[1]) if row else [])\n",
    "            return self.fetch_many(ids)\n",
    "\n",
    "        # For each token, find all candidates and merge them.\n",
    "        return list(itertools.chain(*[one(token) for token in tokens if token]))\n",
    "\n",
    "    def rank_word_frequency(self, tokens, candidates: List[Document]):\n",
    "        \"Candidates with tokens repeated most often\"\n",
    "\n",
    "        df = pd.DataFrame(candidates)\n",
    "        freqs = df.apply(lambda x: Counter(tokenize(x.blob)), axis=\"columns\")\n",
    "        scores = freqs.apply(lambda counter: sum(counter[token] for token in tokens))\n",
    "        df[\"score\"] = scores / scores.sum()\n",
    "        topk = df[df[\"score\"] > 0].sort_values(by=\"score\", ascending=False)\n",
    "        return topk\n",
    "\n",
    "    def __call__(self, query):\n",
    "        tokens = tokenize(query)\n",
    "        candidates = self.candidates(tokens)\n",
    "        return self.rank_word_frequency(tokens, candidates)\n",
    "\n",
    "\n",
    "search = Search(\"search.db\")\n",
    "search(\"monzo\").drop(columns=[\"id\", \"blob\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking with ðŸ¤— Transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598053097724915}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentiment Analysis\n",
    "# 1. Fast enough, but not what I want for search\n",
    "# 2. Should definitely hook this up with my Obsidian notes\n",
    "\n",
    "\n",
    "classifier = pipeline(\n",
    "    \"sentiment-analysis\", model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\", revision=\"af0f99b\"\n",
    ")\n",
    "\n",
    "classifier(\"I've been waiting for a HuggingFace course my whole life.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'This is a course about the Transformers library',\n",
       " 'labels': ['education', 'business', 'politics'],\n",
       " 'scores': [0.8445975184440613, 0.11197522282600403, 0.043427180498838425]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", revision=\"c626438\")\n",
    "\n",
    "classifier(\n",
    "    \"This is a course about the Transformers library\",\n",
    "    candidate_labels=[\"education\", \"politics\", \"business\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'b\\'<!DOCTYPE html>\\\\n<html>\\\\n  <head>\\\\n  <meta charset=\"utf-8\">\\\\n  <meta http-equiv=\"X-UA-Compatible\" content=\"chrome=1\">\\\\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\\\\n\\\\n  <title>This blog doesn&#39;t track you anymore!</title>\\\\n  <meta name=\"description\" content=\"I avoid 3rd party tracking on the web as much as I can with several ad blockersbut then forcing it on the readers of this blog felt very hypocritical.\">\\\\n\\\\n  <link rel=\"stylesheet\" href=\"https://use.fontawesome.com/releases/v5.8.2/css/all.css\" integrity=\"sha384-oS3vJWv+0UjzBfQzYUhtDYW+Pj2yciDJxpsK1OYPAYjqT085Qq/1cq5FLXAZQ7Ay\" crossorigin=\"anonymous\">\\\\n\\\\n  <link rel=\"stylesheet\" href=\"/css/main.css\">\\\\n  <link rel=\"canonical\" href=\"https://blog.jabid.in/2020/02/29/track.html\">\\\\n  <link rel=\"alternate\" type=\"application/rss+xml\" title=\"Jaseem Abid\" href=\"https://blog.jabid.in/feed.xml\">\\\\n</head>\\\\n\\\\n\\\\n  <body>\\\\n\\\\n    <div class=\"wrapper\">\\\\n      <header>\\\\n\\\\n  <a href=\"/\">\\\\n    <img class=\"me\" src=\"/images/me.jpg\" />\\\\n  </a>\\\\n\\\\n  <ul class=\"icons\">\\\\n    <li>\\\\n      <a href=\"/about.html\" title=\"About me\">\\\\n        <i class=\"fa fa-user\"></i>\\\\n      </a>\\\\n    </li>\\\\n\\\\n    <li>\\\\n      <a href=\"https://twitter.com/jaseemabid\" title=\"Twitter\">\\\\n        <i class=\"fab fa-twitter\"></i>\\\\n      </a>\\\\n    </li>\\\\n\\\\n    <li>\\\\n      <a rel=\"me\" href=\"https://bucketofcrabs.club/@jabid\", title=\"Mastodon\">\\\\n        <i class=\"fab fa-mastodon\"></i>\\\\n      </a>\\\\n    </li>\\\\n\\\\n    <li>\\\\n      <a href=\"https://github.com/jaseemabid\" title=\"Github\">\\\\n        <i class=\"fab fa-github\"></i>\\\\n      </a>\\\\n    </li>\\\\n\\\\n    <li>\\\\n      <a href=\"/feed.xml\" title=\"Subscribe to feeds\">\\\\n        <i class=\"fa fa-rss\"></i>\\\\n      </a>\\\\n    </li>\\\\n\\\\n    <li>\\\\n      <a href=\"/Jaseem Abid.pdf\" title=\"Resume\">\\\\n        <i class=\"fa fa-id-card\"></i>\\\\n      </a>\\\\n    </li>\\\\n\\\\n  </ul>\\\\n</header>\\\\n\\\\n      <section>\\\\n\\\\n        <h1>This blog doesn\\\\\\'t track you anymore!</h1>\\\\n\\\\n        <p class=\"post-meta\">\\\\n          <time datetime=\"2020-02-29T00:00:00+00:00\">\\\\n            Feb 29, 2020\\\\n          </time>\\\\n\\\\n        <article>\\\\n          <p>I avoid 3rd party tracking on the web as much as I can with several ad blockers\\\\nbut then forcing it on the readers of this blog felt very hypocritical.</p>\\\\n\\\\n<p>So I\\\\xe2\\\\x80\\\\x99ve removed all Google Analytics from this blog as of now!</p>\\\\n\\\\n<p>Fonts, CSS and some icons are loaded from 3rd party CDNs, which I hope to inline\\\\nsoon. There is a link to Recurse Center below and it contains a unique token for\\\\nthis blog, but it should not track you.</p>\\\\n\\\\n<p>Enjoy your privacy and slightly faster loading times \\\\xf0\\\\x9f\\\\x8f\\\\x8e</p>\\\\n\\\\n        </article>\\\\n\\\\n      <br/><br/>\\\\n      <script async defer src=\"https://www.recurse-scout.com/loader.js?t=298747a8a50ca362138e799f749fcf3f\"></script>\\\\n\\\\n      </section>\\\\n      <footer>\\\\n  <p><small>Hosted on GitHub Pages &mdash; Theme by <a href=\"https://github.com/orderedlist\">orderedlist</a></small></p>\\\\n</footer>\\\\n\\\\n  </body>\\\\n</html>\\\\n\\'',\n",
       " 'labels': ['travel',\n",
       "  'business',\n",
       "  'tourism',\n",
       "  'netherlands',\n",
       "  'politics',\n",
       "  'amsterdam',\n",
       "  'education'],\n",
       " 'scores': [0.21228446066379547,\n",
       "  0.17891483008861542,\n",
       "  0.17562319338321686,\n",
       "  0.15644006431102753,\n",
       "  0.13801610469818115,\n",
       "  0.08728055655956268,\n",
       "  0.051440779119729996]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\n",
    "    str(docs[1].blob),\n",
    "    candidate_labels=[\"amsterdam\", \"netherlands\", \"travel\", \"tourism\", \"education\", \"politics\", \"business\"],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
